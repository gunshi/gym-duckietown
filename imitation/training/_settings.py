import math
import numpy as np
import tensorflow as tf
import pyglet

from gym_duckietown.envs import DuckietownEnv, DuckiebotEnv
from imitation.teachers import UAPurePursuitPolicy

SEED = 19048  # generated by Google Random Generator (1 - 50,000)
DEBUG = False
# seeding
np.random.seed(SEED)
tf.set_random_seed(SEED)

MAP_NAME = 'udem1'
MAP_STARTING_POSES = [
    [[0.8, 0.0, 1.5], 10.90],
    [[0.8, 0.0, 2.5], 10.90],
    [[1.5, 0.0, 3.5], 12.56],
    [[2.5, 0.0, 3.5], 12.56],
    [[4.1, 0.0, 2.0], 14.14],
    [[2.8, 0.0, 0.8], 15.71],
]

# all with Dataset Aggregation
ALGORITHMS = ['supervised', 'dagger', 'aggrevate', 'safe_dagger', 'upms', 'upms-ne', 'upms-sl', 'upms-ne-sl']

# teacher
teacher_name = 'pure_pursuit'

# Task Configuration
HORIZONS = [128, 256, 512, 1024, 2048]
EPISODES = [64, 32, 16, 8, 4]

ITERATIONS = 4  # to 4

SUBMISSION_DIRECTORY = 'icra2019/'


def experimental_entry(algorithm, experiment_iteration, parametrization_name, horizon, episodes,
                       optimization_name, learning_rate):
    return '{}/{}/{}/h{}e{}/{}_{}/{}_lr_{}/'.format(
        SUBMISSION_DIRECTORY,
        algorithm,
        experiment_iteration,
        horizon,
        episodes,
        teacher_name,
        parametrization_name,
        optimization_name,
        learning_rate
    )


def simulation(at):
    environment = DuckietownEnv(
        domain_rand=False,
        max_steps=math.inf,
        map_name=MAP_NAME
    )
    environment.reset()

    environment.cur_pos = np.array(at[0])
    environment.cur_angle = at[1]

    return environment


def robot():
    return DuckiebotEnv()


def teacher(env):
    return UAPurePursuitPolicy(
        env=env,
        following_distance=0.3,
        refresh_rate=1 / 30
    )




